# 故障排除

<cite>
**本文档中引用的文件**
- [README.md](file://README.md)
- [QUICK_START.md](file://QUICK_START.md)
- [NANOCHAT_GRPO_GUIDE.md](file://NANOCHAT_GRPO_GUIDE.md)
- [mlx-grpo.py](file://mlx-grpo.py)
- [convert_nanochat.py](file://convert_nanochat.py)
- [utils/README.md](file://utils/README.md)
- [configs/smoke_test.toml](file://configs/smoke_test.toml)
- [configs/prod.toml](file://configs/prod.toml)
- [pyproject.toml](file://pyproject.toml)
- [test_nanochat_direct.py](file://test_nanochat_direct.py)
</cite>

## 目录
1. [简介](#简介)
2. [常见配置问题](#常见配置问题)
3. [模型转换问题](#模型转换问题)
4. [tiktoken分词器问题](#tiktoken分词器问题)
5. [训练过程问题](#训练过程问题)
6. [内存和性能问题](#内存和性能问题)
7. [检查点恢复问题](#检查点恢复问题)
8. [性能优化建议](#性能优化建议)
9. [调试工具和技巧](#调试工具和技巧)
10. [社区支持资源](#社区支持资源)

## 简介

本故障排除指南汇集了在使用 MLX-GRPO 训练框架过程中可能遇到的常见问题及其解决方案。通过系统化的方法，帮助用户快速定位和解决各种技术问题，减少调试时间。

## 常见配置问题

### Config 文件未找到

**症状：**
```
Config file not found: configs/custom.toml
```

**原因：**
- 配置文件路径不正确
- 文件不存在或拼写错误
- 当前工作目录设置错误

**解决方案：**

1. **验证文件路径**
   ```bash
   # 检查配置文件是否存在
   ls -la configs/custom.toml
   
   # 使用绝对路径
   uv run mlx-grpo.py --config /full/path/to/configs/custom.toml
   ```

2. **检查当前目录**
   ```bash
   # 确认当前工作目录
   pwd
   
   # 切换到项目根目录
   cd /path/to/MLX-GRPO
   ```

3. **验证配置文件格式**
   ```bash
   # 检查 TOML 格式是否正确
   python -c "import tomllib; with open('configs/custom.toml', 'rb') as f: tomllib.load(f)"
   ```

**预防措施：**
- 使用相对路径时确保从项目根目录运行
- 在配置文件中添加注释说明参数含义
- 定期备份重要配置文件

**节来源**
- [QUICK_START.md](file://QUICK_START.md#L200-L210)
- [mlx-grpo.py](file://mlx-grpo.py#L350-L370)

### 未知配置键

**症状：**
```
Unknown config key: invalid_parameter
```

**原因：**
- 配置参数名称拼写错误
- 使用了不存在的参数
- 参数名称大小写错误

**解决方案：**

1. **检查参数名称**
   ```bash
   # 查看有效配置参数列表
   cat configs/smoke_test.toml | grep -v '^#' | grep '='
   ```

2. **参考官方文档**
   - 参考 [CONFIG_GUIDE.md](file://CONFIG_GUIDE.md) 获取完整参数列表
   - 检查参数类型和默认值

3. **正确的参数格式**
   ```bash
   # ✅ 正确：无引号的数值
   uv run mlx-grpo.py --config configs/default.toml --set learning_rate=5e-7
   
   # ❌ 错误：字符串值加引号
   uv run mlx-grpo.py --config configs/default.toml --set learning_rate="5e-7"
   ```

**预防措施：**
- 使用配置文件而非命令行参数进行复杂设置
- 在修改配置前备份原始文件
- 使用 IDE 的语法高亮功能检查 TOML 格式

**节来源**
- [QUICK_START.md](file://QUICK_START.md#L210-L220)

### 值强制转换失败

**症状：**
```
Failed to coerce value: 'invalid_string' to <class 'float'>
```

**原因：**
- 数据类型不匹配
- 字符串格式错误
- 缺少必要的类型转换

**解决方案：**

1. **检查数据类型**
   ```bash
   # 数值型参数不应加引号
   --set learning_rate=1e-6      # ✅ 正确
   --set learning_rate="1e-6"    # ❌ 错误
   ```

2. **验证布尔值格式**
   ```bash
   --set use_compile=true        # ✅ 正确
   --set use_compile=1           # ✅ 正确
   --set use_compile=yes         # ✅ 正确
   --set use_compile=false       # ✅ 正确
   ```

3. **检查整数值**
   ```bash
   --set num_generations=32      # ✅ 正确
   --set num_generations="32"    # ❌ 错误
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L330-L350)

## 模型转换问题

### MLX-LM 源码安装失败

**症状：**
```
ModuleNotFoundError: No module named 'mlx_lm'
```

**原因：**
- MLX-LM 版本过旧
- 源码未正确安装
- Python 环境配置问题

**解决方案：**

1. **从源码安装最新版本**
   ```bash
   # 克隆仓库
   git clone https://github.com/ml-explore/mlx-lm
   cd mlx-lm
   
   # 使用 uv 安装（推荐）
   uv pip install -e .
   
   # 或使用 pip
   pip install -e .
   ```

2. **验证安装**
   ```bash
   uv run python -c "from mlx_lm.models import nanochat; print('✅ MLX-LM 安装成功')"
   ```

3. **检查依赖版本**
   ```bash
   # 确保版本兼容
   python -c "import mlx; print(f'MLX 版本: {mlx.__version__}')"
   python -c "import mlx_lm; print(f'MLX-LM 版本: {mlx_lm.__version__}')"
   ```

**预防措施：**
- 使用 uv 包管理器确保依赖一致性
- 定期更新到最新稳定版本
- 在虚拟环境中隔离项目依赖

**节来源**
- [NANOCHAT_GRPO_GUIDE.md](file://NANOCHAT_GRPO_GUIDE.md#L40-L60)

### 模型转换失败

**症状：**
```
Failed to convert model: torch.load() error
```

**原因：**
- PyTorch 检查点文件损坏
- 内存不足
- 权重映射错误

**解决方案：**

1. **验证模型文件完整性**
   ```python
   # 检查 PyTorch 文件
   import torch
   checkpoint = torch.load('model_000650.pt', map_location='cpu')
   print(f"权重数量: {len(checkpoint)}")
   ```

2. **增加可用内存**
   ```bash
   # macOS 15+ 增加内存限制
   sudo sysctl iogpu.wired_limit_mb=32768
   
   # 或使用更激进的量化
   uv run python utils/convert_model.py \
       --hf-path large/model \
       --quantize \
       --bits 2
   ```

3. **手动权重映射**
   ```python
   # 修改 convert_nanochat.py 中的权重映射函数
   def map_weight_names(key):
       # 添加自定义映射规则
       if 'transformer.' in key:
           return key.replace('transformer.', 'transformer.')
       return key
   ```

**节来源**
- [convert_nanochat.py](file://convert_nanochat.py#L15-L50)

## tiktoken分词器问题

### 分词器加载失败

**症状：**
```
Failed to load tiktoken tokenizer: Pickle file corrupted
```

**原因：**
- Pickle 文件损坏
- tiktoken 版本不兼容
- 文件权限问题

**解决方案：**

1. **重新下载分词器文件**
   ```bash
   # 清理缓存
   rm -rf ~/.cache/huggingface/hub/*
   
   # 重新下载模型
   from huggingface_hub import snapshot_download
   snapshot_download('karpathy/nanochat-d32', allow_patterns=["tokenizer.pkl"])
   ```

2. **验证分词器完整性**
   ```python
   import pickle
   try:
       with open('tokenizer.pkl', 'rb') as f:
           tokenizer = pickle.load(f)
       print(f"词汇表大小: {tokenizer.n_vocab}")
   except Exception as e:
       print(f"分词器加载失败: {e}")
   ```

3. **使用替代分词器**
   ```python
   # 如果 tiktoken 加载失败，回退到标准分词器
   from transformers import AutoTokenizer
   tokenizer = AutoTokenizer.from_pretrained('gpt2')
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L207-L225)

### 文本生成出现乱码

**症状：**
```
M don yourty youon insOifissty youon insM don features T...
```

**原因：**
- 分词器不匹配
- 词汇表 ID 不对应
- 嵌入矩阵使用错误

**解决方案：**

1. **验证分词器匹配**
   ```python
   # 检查词汇表大小
   print(f"模型词汇表: {tokenizer.n_vocab}")
   print(f"期望词汇表: 65536")
   
   # 测试编码解码
   test_text = "The capital of France is"
   encoded = tokenizer.encode(test_text)
   decoded = tokenizer.decode(encoded)
   print(f"原始: {test_text}")
   print(f"编码: {encoded}")
   print(f"解码: {decoded}")
   ```

2. **使用正确的分词器**
   ```python
   # 确保使用原始 tiktoken 分词器
   from mlx_lm import load
   model, tokenizer = load("models/nanochat-mlx")
   
   # 验证生成质量
   response = generate(model, tokenizer, prompt="The capital of France is", max_tokens=20)
   print(response)
   ```

**节来源**
- [NANOCHAT_GRPO_GUIDE.md](file://NANOCHAT_GRPO_GUIDE.md#L200-L250)

## 训练过程问题

### NaN 梯度错误

**症状：**
```
RuntimeError: NaN gradient encountered
```

**原因：**
- 学习率过高
- 模型不稳定
- 数值精度问题

**解决方案：**

1. **降低学习率**
   ```toml
   # 修改配置文件
   learning_rate = 1e-6  # 从 5e-6 降低到 1e-6
   ```

2. **启用梯度裁剪**
   ```toml
   max_grad_norm = 1.0  # 设置合理的梯度裁剪阈值
   ```

3. **禁用量化（对于大模型）**
   ```toml
   quantize_for_rollouts = false  # 对于 32 层模型必须禁用
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L1000-L1030)

### 训练收敛缓慢

**症状：**
- 奖励分数长时间为零
- 损失函数不下降
- 生成质量没有改善

**解决方案：**

1. **调整采样参数**
   ```toml
   # 增加生成数量以获得更好的多样性
   num_generations = 16  # 从 4 增加到 16
   
   # 增加最大新令牌数
   max_new_tokens = 128  # 从 64 增加到 128
   ```

2. **改进奖励函数**
   ```python
   # 添加更多奖励函数
   reward_functions = [
       correctness_reward_func,
       int_reward_func,
       strict_format_reward_func,
       xmlcount_reward_func
   ]
   ```

3. **增加训练样本**
   ```toml
   max_train_samples = 1000  # 从 500 增加到 1000
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L400-L450)

### 模型生成重复

**症状：**
```
The capital of France is Paris. The capital of France is Paris. The capital of France is Paris...
```

**原因：**
- 重复惩罚不足
- 温度过低
- 模型过拟合

**解决方案：**

1. **增加重复惩罚**
   ```toml
   repetition_penalty = 1.2  # 默认值为 1.0
   ```

2. **调整温度**
   ```toml
   temperature = 0.8  # 从 0.7 增加到 0.8
   ```

3. **改进采样策略**
   ```python
   # 在 generate_responses 函数中
   sampler = make_sampler(temperature, top_p=0.95, min_p=0.0, min_tokens_to_keep=1)
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L450-L500)

## 内存和性能问题

### 内存不足（OOM）错误

**症状：**
```
OutOfMemoryError: Unable to allocate memory
```

**原因：**
- 模型过大
- 批次大小过高
- 量化设置不当

**解决方案：**

1. **减少批次大小**
   ```toml
   batch_size = 1  # 保持为 1 以节省内存
   gradient_accumulation_steps = 4  # 增加累积步数
   ```

2. **启用量化**
   ```toml
   quantize_for_rollouts = true  # 启用 4-bit 量化
   ```

3. **增加系统内存限制**
   ```bash
   # macOS 15+ 增加内存限制
   sudo sysctl iogpu.wired_limit_mb=32768
   
   # 检查当前限制
   sysctl iogpu.wired_limit_mb
   ```

4. **监控内存使用**
   ```bash
   # 使用活动监视器监控内存使用
   # 或使用命令行工具
   ps aux | grep python
   ```

**节来源**
- [utils/README.md](file://utils/README.md#L350-L370)

### 训练速度慢

**症状：**
- 单步训练时间过长
- CPU 使用率低
- GPU 利用率不足

**解决方案：**

1. **启用编译优化**
   ```toml
   use_compile = true  # 启用 MLX 编译
   ```

2. **调整生成参数**
   ```toml
   # 减少生成长度以提高速度
   max_new_tokens = 64  # 从 256 减少到 64
   ```

3. **优化采样策略**
   ```python
   # 使用更高效的采样方法
   sampler = make_sampler(temperature, top_p=0.9, min_p=0.0)
   ```

4. **批量生成优化**
   ```python
   # 在 generate_responses 中尝试批量生成
   try:
       outputs = mlx_generate(
           self.model_old,
           self.tokenizer,
           prompt=prompts,
           max_tokens=self.args.max_new_tokens,
           sampler=sampler
       )
   except Exception:
       # 回退到逐个生成
       pass
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L500-L550)

### 性能瓶颈分析

**诊断步骤：**

1. **识别瓶颈位置**
   ```python
   import time
   
   start_time = time.time()
   # 训练步骤
   elapsed = time.time() - start_time
   print(f"训练步骤耗时: {elapsed:.2f} 秒")
   ```

2. **内存使用分析**
   ```python
   import psutil
   import os
   
   process = psutil.Process(os.getpid())
   memory_mb = process.memory_info().rss / 1024 / 1024
   print(f"内存使用: {memory_mb:.2f} MB")
   ```

3. **GPU 利用率监控**
   ```bash
   # 使用系统监控工具
   # 或在代码中添加日志
   print(f"GPU 内存使用: {mx.gpu_memory_used()}")
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L600-L650)

## 检查点恢复问题

### 检查点保存失败

**症状：**
```
Failed to save checkpoint: Permission denied
```

**原因：**
- 输出目录权限不足
- 磁盘空间不足
- 文件系统错误

**解决方案：**

1. **检查目录权限**
   ```bash
   # 创建输出目录并设置权限
   mkdir -p outputs/checkpoint_dir
   chmod 755 outputs/checkpoint_dir
   
   # 验证权限
   ls -la outputs/
   ```

2. **检查磁盘空间**
   ```bash
   df -h
   du -sh outputs/
   ```

3. **验证文件写入**
   ```python
   # 测试文件写入能力
   try:
       with open('test_file.txt', 'w') as f:
           f.write('test')
       os.remove('test_file.txt')
   except Exception as e:
       print(f"文件写入失败: {e}")
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L711-L780)

### 检查点加载失败

**症状：**
```
Checkpoint not found: outputs/checkpoint-1000
```

**原因：**
- 检查点路径错误
- 文件损坏
- 权限问题

**解决方案：**

1. **验证检查点存在**
   ```bash
   # 检查检查点目录
   ls -la outputs/checkpoint-1000/
   
   # 验证必要文件
   ls -la outputs/checkpoint-1000/ | grep -E "(model\.safetensors|config\.json|tokenizer\.json)"
   ```

2. **手动复制检查点**
   ```bash
   # 复制检查点到新位置
   cp -r outputs/checkpoint-1000/ new_checkpoint/
   ```

3. **修复损坏的检查点**
   ```python
   # 手动验证模型权重
   import mlx.core as mx
   try:
       weights = mx.load("outputs/checkpoint-1000/model.safetensors")
       print(f"权重数量: {len(weights)}")
   except Exception as e:
       print(f"权重加载失败: {e}")
   ```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L780-L820)

## 性能优化建议

### 模型量化优化

**量化策略对比：**

| 量化位数 | 内存节省 | 速度提升 | 质量损失 | 推荐场景 |
|----------|----------|----------|----------|----------|
| 8-bit | 25% | 10-15% | 微小 | 大模型推理 |
| 4-bit | 50% | 20-30% | 显著 | 训练和推理 |
| 2-bit | 75% | 30-40% | 较大 | 内存受限环境 |

**实施建议：**
```toml
# 生产环境配置
quantize_for_rollouts = true    # 启用量化
bits = 4                        # 4-bit 量化
group_size = 64                 # 组量化大小
```

### 批处理优化

**批处理策略：**

1. **动态批处理**
   ```python
   # 根据可用内存动态调整批次大小
   def dynamic_batch_size(memory_available):
       if memory_available > 16 * 1024 * 1024 * 1024:  # 16GB
           return 4
       elif memory_available > 8 * 1024 * 1024 * 1024:  # 8GB
           return 2
       else:
           return 1
   ```

2. **梯度累积**
   ```toml
   batch_size = 1
   gradient_accumulation_steps = 4  # 等效批次大小为 4
   ```

### 缓存优化

**缓存策略：**

1. **模型权重缓存**
   ```bash
   # 设置 Hugging Face 缓存目录
   export HF_HOME=/path/to/fast/storage/cache
   ```

2. **临时文件清理**
   ```bash
   # 定期清理临时文件
   find /tmp -name "mlx_*" -mtime +1 -delete
   ```

**节来源**
- [utils/README.md](file://utils/README.md#L400-L450)

## 调试工具和技巧

### 日志分析

**启用详细日志：**
```toml
# 在配置中启用详细日志
log_jsonl = true
logging_steps = 1
```

**日志分析脚本：**
```python
import json
import pandas as pd

# 分析训练日志
def analyze_training_log(log_file):
    with open(log_file, 'r') as f:
        logs = [json.loads(line) for line in f]
    
    df = pd.DataFrame(logs)
    
    # 检查异常值
    print("异常奖励值:")
    print(df[df['reward_mean'] > 10])
    
    # 检查梯度范数
    print("异常梯度范数:")
    print(df[df['grad_norm'] > 10])
    
    return df
```

### 性能监控

**实时监控脚本：**
```python
import time
import psutil
import mlx.core as mx

def monitor_training():
    while True:
        # 内存使用
        mem = psutil.virtual_memory()
        gpu_mem = mx.gpu_memory_used()
        
        # GPU 利用率
        gpu_util = mx.gpu_utilization()
        
        print(f"内存: {mem.percent}% ({gpu_mem/1024/1024:.1f}MB)")
        print(f"GPU: {gpu_util:.1f}%")
        
        time.sleep(5)
```

### 调试模式

**启用调试模式：**
```toml
# 在配置中启用调试选项
use_compile = false
num_generations = 2  # 减少生成数量
max_train_samples = 10  # 减少训练样本
```

**断点调试：**
```python
import pdb

# 在关键位置设置断点
def generate_responses(self, batch):
    pdb.set_trace()  # 进入调试模式
    # 原有代码...
```

**节来源**
- [mlx-grpo.py](file://mlx-grpo.py#L300-L350)

## 社区支持资源

### 官方资源

1. **GitHub 仓库**
   - 主仓库: https://github.com/Doriandarko/MLX-GRPO
   - MLX-LM: https://github.com/ml-explore/mlx-lm
   - MLX: https://github.com/ml-explore/mlx

2. **文档和教程**
   - [Quick Start Guide](QUICK_START.md)
   - [NanoChat GRPO Guide](NANOCHAT_GRPO_GUIDE.md)
   - [Utils README](utils/README.md)

### 常见问题解答

**Q: 如何选择合适的模型？**
A: 根据可用内存和任务需求选择：
- 小模型 (< 8GB RAM): nanochat (20层)
- 中等模型 (8-16GB RAM): Qwen2.5-1.5B
- 大模型 (> 16GB RAM): nanochat-d32 (32层)

**Q: 训练需要多长时间？**
A: 训练时间取决于：
- 模型大小: 20层模型 ~1小时，32层模型 ~3小时
- 训练样本: 500样本 ~30分钟
- 硬件性能: M1 Pro ~2倍于 M1 Mac

**Q: 如何验证训练效果？**
A: 使用评估指标：
- 准确率 (Accuracy)
- Exact Match (EM)
- 奖励分数分布

### 报告问题

当遇到无法解决的问题时，请提供以下信息：

1. **系统信息**
   ```bash
   # macOS 版本
   sw_vers
   
   # Python 版本
   python --version
   
   # MLX 版本
   python -c "import mlx; print(mlx.__version__)"
   ```

2. **错误日志**
   - 完整的错误堆栈跟踪
   - 相关的配置文件内容
   - 最后 100 行的日志输出

3. **重现步骤**
   - 详细的命令序列
   - 使用的配置文件
   - 模型文件信息

### 贡献指南

欢迎贡献改进：
- 改进文档
- 添加新的故障排除案例
- 提供性能优化建议
- 修复已知问题

通过遵循本故障排除指南，用户应该能够有效地诊断和解决在使用 MLX-GRPO 训练框架过程中遇到的各种问题。如果问题仍然存在，可以参考官方文档或向社区寻求帮助。